{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, year, month, dayofmonth, dayofweek, datediff, to_date, regexp_replace, length, unix_timestamp, from_unixtime, log\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, LinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from constants import TEST_TRANSFORMED_DATA, TRAIN_TRANSFORMED_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"CO2 Emission ML Pipeline - Modelling\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#reading df\n",
    "TEST_TRANSFORMED_DF = spark.read.parquet(TEST_TRANSFORMED_DATA)\n",
    "TRAIN_TRANSFORMED_DF = spark.read.parquet(TRAIN_TRANSFORMED_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns \n",
    "categorical_columns = [\"transport_mode\", \"project_location\", \"material_category\", \"supplier_location\"]\n",
    "# list of scaled columns\n",
    "columns_to_scale = [\"Quantity_Squared\", \"Distance_Covered_Squared\", \"Quantity_Distance_Interaction\", \"supplier_rating\", \"Transaction_Year\", \"Transaction_Month\", \"project_duration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/14 00:23:00 WARN Instrumentation: [7dedc208] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.0529085351593626\n",
      "R-squared on test data = 0.3258366813389463\n"
     ]
    }
   ],
   "source": [
    "# initialize the Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"log_CO2_emission\")\n",
    "\n",
    "# train model\n",
    "lr_model = lr.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# predict on the test data\n",
    "lr_predictions = lr_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# evaluate the model\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "lr_rmse = lr_evaluator.evaluate(lr_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {lr_rmse}\")\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "lr_r2 = lr_evaluator.evaluate(lr_predictions)\n",
    "print(f\"R-squared on test data = {lr_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1013.0 KiB\n",
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1064.1 KiB\n",
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1063.7 KiB\n",
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1064.1 KiB\n",
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1064.8 KiB\n",
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1065.9 KiB\n",
      "23/11/14 00:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1068.1 KiB\n",
      "23/11/14 00:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1072.8 KiB\n",
      "23/11/14 00:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1081.3 KiB\n",
      "23/11/14 00:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1097.9 KiB\n",
      "23/11/14 00:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1126.5 KiB\n",
      "23/11/14 00:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1173.5 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1001.9 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1006.7 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1015.9 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1033.7 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1066.0 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1118.8 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1115.7 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1116.2 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1116.9 KiB\n",
      "23/11/14 00:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1117.9 KiB\n",
      "23/11/14 00:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1120.3 KiB\n",
      "23/11/14 00:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1124.7 KiB\n",
      "23/11/14 00:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1133.0 KiB\n",
      "23/11/14 00:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1149.6 KiB\n",
      "23/11/14 00:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1177.4 KiB\n",
      "23/11/14 00:23:27 WARN DAGScheduler: Broadcasting large task binary with size 1220.2 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1218.4 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1218.9 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1219.6 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1220.6 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1222.9 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1227.3 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1236.2 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1253.8 KiB\n",
      "23/11/14 00:23:28 WARN DAGScheduler: Broadcasting large task binary with size 1285.5 KiB\n",
      "23/11/14 00:23:29 WARN DAGScheduler: Broadcasting large task binary with size 1334.9 KiB\n",
      "23/11/14 00:23:38 WARN DAGScheduler: Broadcasting large task binary with size 1004.6 KiB\n",
      "23/11/14 00:23:38 WARN DAGScheduler: Broadcasting large task binary with size 1023.0 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1055.5 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1111.0 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1112.2 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1112.7 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1113.4 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1114.4 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1116.7 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1121.3 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1130.4 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1146.1 KiB\n",
      "23/11/14 00:23:39 WARN DAGScheduler: Broadcasting large task binary with size 1170.1 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1204.3 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1199.1 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1199.6 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1200.3 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1201.3 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1203.6 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1208.2 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1217.5 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1233.4 KiB\n",
      "23/11/14 00:23:40 WARN DAGScheduler: Broadcasting large task binary with size 1257.3 KiB\n",
      "23/11/14 00:23:41 WARN DAGScheduler: Broadcasting large task binary with size 1292.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data with CV = 0.5764742370042398\n",
      "R-squared on test data with CV = 0.7979105542889521\n"
     ]
    }
   ],
   "source": [
    "# initialize GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"log_CO2_emission\")\n",
    "\n",
    "# create parameter grid \n",
    "gbt_paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(gbt.maxDepth, [5, 10])\n",
    "                 .addGrid(gbt.maxBins, [16])\n",
    "                 .addGrid(gbt.maxIter, [10])\n",
    "                 .build())\n",
    "\n",
    "# initialize evaluator with the appropriate metric - rmse\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# 5-fold CrossValidator\n",
    "gbt_cv = CrossValidator(estimator=gbt,\n",
    "                        estimatorParamMaps=gbt_paramGrid,\n",
    "                        evaluator=gbt_evaluator,\n",
    "                        numFolds=3)\n",
    "\n",
    "# run cross-validation\n",
    "gbt_cv_model = gbt_cv.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# predict on the test data\n",
    "gbt_cv_predictions = gbt_cv_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# evaluate the model\n",
    "gbt_cv_rmse = gbt_evaluator.evaluate(gbt_cv_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data with CV = {gbt_cv_rmse}\")\n",
    "\n",
    "# To evaluate R-squared\n",
    "gbt_evaluator.setMetricName(\"r2\")\n",
    "gbt_cv_r2 = gbt_evaluator.evaluate(gbt_cv_predictions)\n",
    "print(f\"R-squared on test data with CV = {gbt_cv_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/14 00:23:48 WARN DAGScheduler: Broadcasting large task binary with size 1393.3 KiB\n",
      "23/11/14 00:23:51 WARN DAGScheduler: Broadcasting large task binary with size 1303.6 KiB\n",
      "23/11/14 00:23:52 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/14 00:23:53 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/11/14 00:23:58 WARN DAGScheduler: Broadcasting large task binary with size 1381.6 KiB\n",
      "23/11/14 00:24:01 WARN DAGScheduler: Broadcasting large task binary with size 1306.0 KiB\n",
      "23/11/14 00:24:02 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/14 00:24:03 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/11/14 00:24:07 WARN DAGScheduler: Broadcasting large task binary with size 1399.9 KiB\n",
      "23/11/14 00:24:10 WARN DAGScheduler: Broadcasting large task binary with size 1307.2 KiB\n",
      "23/11/14 00:24:11 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/14 00:24:12 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "23/11/14 00:24:15 WARN DAGScheduler: Broadcasting large task binary with size 1238.3 KiB\n",
      "23/11/14 00:24:16 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/14 00:24:17 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on CV test data = 0.5538786257349492\n",
      "R-squared on CV test data = 0.8134423603666683\n"
     ]
    }
   ],
   "source": [
    "# initialize RandomForest regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"log_CO2_emission\")\n",
    "\n",
    "# parameter grid \n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [10, 30])  # List of trees to test\n",
    "             .addGrid(rf.maxDepth, [5, 10])    # List of maximum depths to test\n",
    "             .addGrid(rf.maxBins, [32])        # List of bins to test\n",
    "             .build())\n",
    "\n",
    "# evaluator for the cross-validation\n",
    "evaluator = RegressionEvaluator(labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# crossValidator requires the same evaluator used to evaluate the model\n",
    "cv = CrossValidator(estimator=rf,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3)  # Number of folds for cross-validation\n",
    "\n",
    "# run cross-validation\n",
    "cv_model = cv.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# Use the best model found to make predictions on the test data\n",
    "cv_predictions = cv_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# evaluate best model\n",
    "cv_rmse = evaluator.evaluate(cv_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on CV test data = {cv_rmse}\")\n",
    "\n",
    "#R-squared eevaluation\n",
    "evaluator.setMetricName(\"r2\")\n",
    "cv_r2 = evaluator.evaluate(cv_predictions)\n",
    "print(f\"R-squared on CV test data = {cv_r2}\")\n",
    "\n",
    "# Get best model\n",
    "best_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Outcome\n",
    "The results show that both the Gradient Boosted Trees (GBT) and Random Forest Regressor models have performed significantly better than the Linear Regression model in terms of both RMSE and R-squared. The RMSE is lower for the GBT and Random Forest models, indicating better accuracy, and the R-squared values are significantly higher, suggesting that these models explain a much greater proportion of the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance Analysis\n",
    "Analyzing feature importance is a crucial step in understanding and interpreting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Feature Importance\n",
    "I'm taking Random Forest Regressor as my model of choice\n",
    "With PySpark we can use the attribute 'featureImportances' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity_Distance_Interaction: 0.6167063311225728\n",
      "Quantity_Squared: 0.19594874684452945\n",
      "Distance_Covered_Squared: 0.12366560907271244\n",
      "log_project_budget: 0.014118016637641388\n",
      "Transaction_Month: 0.011746204243516654\n",
      "supplier_rating: 0.00670079278111016\n",
      "project_duration: 0.005178558064682412\n",
      "Transaction_Year: 0.004365846588385062\n",
      "project_location_1: 0.002889254376436291\n",
      "transport_mode_0: 0.002867409315901708\n",
      "transport_mode_1: 0.0024417834859516373\n",
      "material_category_1: 0.002415101831442552\n",
      "supplier_location_0: 0.0023232044778321043\n",
      "project_location_2: 0.0022809302618376375\n",
      "material_category_0: 0.002238708897005056\n",
      "supplier_location_1: 0.0021383195204839793\n",
      "project_location_0: 0.0019751824779586213\n"
     ]
    }
   ],
   "source": [
    "importances = best_rf_model.featureImportances.toArray()\n",
    "\n",
    "# Start with an empty list for feature names\n",
    "feature_names = []\n",
    "\n",
    "# Add names for the one-hot encoded categorical features\n",
    "# You need to know the number of categories in each categorical feature after one-hot encoding\n",
    "for categoricalCol in categorical_columns:\n",
    "    # Assuming we know the number of categories for each column (replace with actual number)\n",
    "    num_categories = TRAIN_TRANSFORMED_DF.select(categoricalCol + \"Vec\").head()[0].size\n",
    "    feature_names += [f\"{categoricalCol}_{i}\" for i in range(num_categories)]\n",
    "\n",
    "# Add names for the scaled numerical features\n",
    "feature_names += columns_to_scale\n",
    "\n",
    "# Add the log-transformed features if they are also included\n",
    "feature_names.append(\"log_project_budget\")\n",
    "\n",
    "# The length of feature names should now match the length of importances\n",
    "assert len(feature_names) == len(importances), f\"Length of feature names ({len(feature_names)}) does not match the number of importances ({len(importances)})\"\n",
    "\n",
    "# Now you can match the importances to the feature names\n",
    "named_importances = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the feature importances\n",
    "for name, importance in named_importances:\n",
    "    print(f\"{name}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_co2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
