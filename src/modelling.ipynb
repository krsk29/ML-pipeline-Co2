{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, year, month, dayofmonth, dayofweek, datediff, to_date, regexp_replace, length, unix_timestamp, from_unixtime, log\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler, \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, LinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from constants import TEST_TRANSFORMED_DATA, TRAIN_TRANSFORMED_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/11/13 23:42:05 WARN Utils: Your hostname, Kris resolves to a loopback address: 127.0.1.1; using 172.18.209.221 instead (on interface eth0)\n",
      "23/11/13 23:42:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/13 23:42:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"CO2 Emission ML Pipeline - Modelling\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#reading df\n",
    "TEST_TRANSFORMED_DF = spark.read.parquet(TEST_TRANSFORMED_DATA)\n",
    "TRAIN_TRANSFORMED_DF = spark.read.parquet(TRAIN_TRANSFORMED_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns \n",
    "categorical_columns = [\"transport_mode\", \"project_location\", \"material_category\", \"supplier_location\"]\n",
    "# list of scaled columns\n",
    "columns_to_scale = [\"Quantity_Squared\", \"Distance_Covered_Squared\", \"Quantity_Distance_Interaction\", \"supplier_rating\", \"Transaction_Year\", \"Transaction_Month\", \"project_duration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/13 23:42:21 WARN Instrumentation: [cffed22e] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/11/13 23:42:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/11/13 23:42:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.0529085351593626\n",
      "R-squared on test data = 0.3258366813389463\n"
     ]
    }
   ],
   "source": [
    "# initialize the Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"log_CO2_emission\")\n",
    "\n",
    "# train model\n",
    "lr_model = lr.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# predict on the test data\n",
    "lr_predictions = lr_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# evaluate the model\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "lr_rmse = lr_evaluator.evaluate(lr_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {lr_rmse}\")\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "lr_r2 = lr_evaluator.evaluate(lr_predictions)\n",
    "print(f\"R-squared on test data = {lr_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1013.0 KiB\n",
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1064.1 KiB\n",
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1063.7 KiB\n",
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1064.1 KiB\n",
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1064.8 KiB\n",
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1065.9 KiB\n",
      "23/11/13 23:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1068.1 KiB\n",
      "23/11/13 23:45:08 WARN DAGScheduler: Broadcasting large task binary with size 1072.8 KiB\n",
      "23/11/13 23:45:08 WARN DAGScheduler: Broadcasting large task binary with size 1081.3 KiB\n",
      "23/11/13 23:45:08 WARN DAGScheduler: Broadcasting large task binary with size 1097.9 KiB\n",
      "23/11/13 23:45:08 WARN DAGScheduler: Broadcasting large task binary with size 1126.5 KiB\n",
      "23/11/13 23:45:08 WARN DAGScheduler: Broadcasting large task binary with size 1173.5 KiB\n",
      "23/11/13 23:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1001.9 KiB\n",
      "23/11/13 23:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1006.7 KiB\n",
      "23/11/13 23:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1015.9 KiB\n",
      "23/11/13 23:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1033.7 KiB\n",
      "23/11/13 23:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1066.0 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1118.8 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1115.7 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1116.2 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1116.9 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1117.9 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1120.3 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1124.7 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1133.0 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1149.6 KiB\n",
      "23/11/13 23:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1177.4 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1220.2 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1218.4 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1218.9 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1219.6 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1220.6 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1222.9 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1227.3 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1236.2 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1253.8 KiB\n",
      "23/11/13 23:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1285.5 KiB\n",
      "23/11/13 23:45:22 WARN DAGScheduler: Broadcasting large task binary with size 1334.9 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1004.6 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1023.0 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1055.5 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1111.0 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1112.2 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1112.7 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1113.4 KiB\n",
      "23/11/13 23:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1114.4 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1116.7 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1121.3 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1130.4 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1146.1 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1170.1 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1204.3 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1199.1 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1199.6 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1200.3 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1201.3 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1203.6 KiB\n",
      "23/11/13 23:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1208.2 KiB\n",
      "23/11/13 23:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1217.5 KiB\n",
      "23/11/13 23:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1233.4 KiB\n",
      "23/11/13 23:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1257.3 KiB\n",
      "23/11/13 23:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1292.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data with CV = 0.5764742370042398\n",
      "R-squared on test data with CV = 0.7979105542889521\n"
     ]
    }
   ],
   "source": [
    "# initialize GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"log_CO2_emission\")\n",
    "\n",
    "# create parameter grid \n",
    "gbt_paramGrid = (ParamGridBuilder()\n",
    "                 .addGrid(gbt.maxDepth, [5, 10])\n",
    "                 .addGrid(gbt.maxBins, [16])\n",
    "                 .addGrid(gbt.maxIter, [10])\n",
    "                 .build())\n",
    "\n",
    "# initialize evaluator with the appropriate metric - rmse\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# 5-fold CrossValidator\n",
    "gbt_cv = CrossValidator(estimator=gbt,\n",
    "                        estimatorParamMaps=gbt_paramGrid,\n",
    "                        evaluator=gbt_evaluator,\n",
    "                        numFolds=3)\n",
    "\n",
    "# run cross-validation\n",
    "gbt_cv_model = gbt_cv.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# predict on the test data\n",
    "gbt_cv_predictions = gbt_cv_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# evaluate the model\n",
    "gbt_cv_rmse = gbt_evaluator.evaluate(gbt_cv_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data with CV = {gbt_cv_rmse}\")\n",
    "\n",
    "# To evaluate R-squared\n",
    "gbt_evaluator.setMetricName(\"r2\")\n",
    "gbt_cv_r2 = gbt_evaluator.evaluate(gbt_cv_predictions)\n",
    "print(f\"R-squared on test data with CV = {gbt_cv_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/13 23:42:24 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "WARNING: An illegal reflective access operation has occurred                    \n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/krisko/ML-pipeline-Co2/venv_co2/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/11/13 23:42:35 WARN DAGScheduler: Broadcasting large task binary with size 1393.3 KiB\n",
      "23/11/13 23:42:40 WARN DAGScheduler: Broadcasting large task binary with size 1303.6 KiB\n",
      "23/11/13 23:42:41 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/13 23:42:42 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/11/13 23:42:49 WARN DAGScheduler: Broadcasting large task binary with size 1381.6 KiB\n",
      "23/11/13 23:42:54 WARN DAGScheduler: Broadcasting large task binary with size 1306.0 KiB\n",
      "23/11/13 23:42:55 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/13 23:42:56 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/11/13 23:43:02 WARN DAGScheduler: Broadcasting large task binary with size 1399.9 KiB\n",
      "23/11/13 23:43:06 WARN DAGScheduler: Broadcasting large task binary with size 1307.2 KiB\n",
      "23/11/13 23:43:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/13 23:43:08 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "23/11/13 23:43:12 WARN DAGScheduler: Broadcasting large task binary with size 1238.3 KiB\n",
      "23/11/13 23:43:13 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/11/13 23:43:14 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on CV test data = 0.5538786257349492\n",
      "R-squared on CV test data = 0.8134423603666683\n"
     ]
    }
   ],
   "source": [
    "# initialize RandomForest regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"log_CO2_emission\")\n",
    "\n",
    "# parameter grid \n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [10, 30])  # List of trees to test\n",
    "             .addGrid(rf.maxDepth, [5, 10])    # List of maximum depths to test\n",
    "             .addGrid(rf.maxBins, [32])        # List of bins to test\n",
    "             .build())\n",
    "\n",
    "# evaluator for the cross-validation\n",
    "evaluator = RegressionEvaluator(labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# crossValidator requires the same evaluator used to evaluate the model\n",
    "cv = CrossValidator(estimator=rf,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3)  # Number of folds for cross-validation\n",
    "\n",
    "# run cross-validation\n",
    "cv_model = cv.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# Use the best model found to make predictions on the test data\n",
    "cv_predictions = cv_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# evaluate best model\n",
    "cv_rmse = evaluator.evaluate(cv_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on CV test data = {cv_rmse}\")\n",
    "\n",
    "#R-squared eevaluation\n",
    "evaluator.setMetricName(\"r2\")\n",
    "cv_r2 = evaluator.evaluate(cv_predictions)\n",
    "print(f\"R-squared on CV test data = {cv_r2}\")\n",
    "\n",
    "# Get best model\n",
    "best_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Outcome\n",
    "The results show that both the Gradient Boosted Trees (GBT) and Random Forest Regressor models have performed significantly better than the Linear Regression model in terms of both RMSE and R-squared. The RMSE is lower for the GBT and Random Forest models, indicating better accuracy, and the R-squared values are significantly higher, suggesting that these models explain a much greater proportion of the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance Analysis\n",
    "Analyzing feature importance is a crucial step in understanding and interpreting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Feature Importance\n",
    "I'm taking Random Forest Regressor as my model of choice\n",
    "With PySpark we can use the attribute 'featureImportances' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature importances\n",
    "rf_feature_importances = best_rf_model.featureImportances.toArray()\n",
    "\n",
    "# create a pandas df for easier visualization\n",
    "features_df = pd.DataFrame(list(zip(TRAIN_TRANSFORMED_DF.columns, rf_feature_importances)),\n",
    "                           columns=[\"feature\", \"importance\"]).sort_values(by=\"importance\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>project_end_date</td>\n",
       "      <td>0.616706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>project_name</td>\n",
       "      <td>0.195949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>project_start_date</td>\n",
       "      <td>0.123666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>supplier_name</td>\n",
       "      <td>0.014118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>material_name</td>\n",
       "      <td>0.011746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>project_location</td>\n",
       "      <td>0.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>material_category</td>\n",
       "      <td>0.005179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>supplier_id</td>\n",
       "      <td>0.004366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transaction_id</td>\n",
       "      <td>0.002889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>material_id</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project_id</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transport_mode</td>\n",
       "      <td>0.002415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>distance_covered</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transaction_date</td>\n",
       "      <td>0.002281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CO2_emission</td>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project_budget</td>\n",
       "      <td>0.001975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "11    project_end_date    0.616706\n",
       "9         project_name    0.195949\n",
       "10  project_start_date    0.123666\n",
       "16       supplier_name    0.014118\n",
       "14       material_name    0.011746\n",
       "12    project_location    0.006701\n",
       "15   material_category    0.005179\n",
       "13         supplier_id    0.004366\n",
       "3       transaction_id    0.002889\n",
       "0          material_id    0.002867\n",
       "1           project_id    0.002442\n",
       "6       transport_mode    0.002415\n",
       "7     distance_covered    0.002323\n",
       "4     transaction_date    0.002281\n",
       "5             quantity    0.002239\n",
       "8         CO2_emission    0.002138\n",
       "2       project_budget    0.001975"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.573318\n"
     ]
    }
   ],
   "source": [
    "# Define the regression model\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='log_CO2_emission')\n",
    "\n",
    "# Train the model\n",
    "rf_model = rf.fit(TRAIN_TRANSFORMED_DF)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_model.transform(TEST_TRANSFORMED_DF)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"log_CO2_emission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "# You can save the trained model for later use or for deployment\n",
    "# rf_model.save(\"path_to_save_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>project_end_date</td>\n",
       "      <td>0.676418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>project_name</td>\n",
       "      <td>0.218012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>project_start_date</td>\n",
       "      <td>0.100544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>supplier_name</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>material_name</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>project_location</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>material_category</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project_budget</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>supplier_id</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>material_id</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project_id</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>distance_covered</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transaction_id</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transaction_date</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transport_mode</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CO2_emission</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "11    project_end_date    0.676418\n",
       "9         project_name    0.218012\n",
       "10  project_start_date    0.100544\n",
       "16       supplier_name    0.001156\n",
       "14       material_name    0.000815\n",
       "12    project_location    0.000598\n",
       "15   material_category    0.000492\n",
       "2       project_budget    0.000351\n",
       "13         supplier_id    0.000346\n",
       "0          material_id    0.000309\n",
       "1           project_id    0.000234\n",
       "5             quantity    0.000171\n",
       "7     distance_covered    0.000169\n",
       "3       transaction_id    0.000148\n",
       "4     transaction_date    0.000134\n",
       "6       transport_mode    0.000078\n",
       "8         CO2_emission    0.000026"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract feature importances\n",
    "rf_feature_importancesss = rf_model.featureImportances.toArray()\n",
    "\n",
    "# create a pandas df for easier visualization\n",
    "features_dfff = pd.DataFrame(list(zip(TRAIN_TRANSFORMED_DF.columns, rf_feature_importancesss)),\n",
    "                           columns=[\"feature\", \"importance\"]).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "features_dfff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_co2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
