{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, year, month, dayofmonth, dayofweek, datediff\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from constants import LOGISTICS_DATA, MATERIALS_DATA, PROJECTS_DATA, SUPPLIERS_DATA, DATA, FINAL_DATA_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notbeook I do some durther preprocessing and data engineering. There are still questions I want to answer about the final data:\n",
    "\n",
    "- Data Summary: A statistical summary of the dataset's numerical columns (mean, median, standard deviation, min, max)\n",
    "- Cardinality of Categorical Features: Knowing how many unique values some of the categorical features have (e.g., transport_mode, project_location, supplier_location) can inform the feature engineering steps\n",
    "- Correlations: Understanding the correlation between the features, especially with the target variable (CO2_emissions) if it's a supervised learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CO2 Emission ML Pipeline - Data Preprocessing\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+--------------+----------------+--------+--------------+------------------+------------------+------------+------------------+----------------+----------------+-----------+-------------+-----------------+-------------+-----------------+---------------+\n",
      "|material_id|project_id|    project_budget|transaction_id|transaction_date|quantity|transport_mode|  distance_covered|      CO2_emission|project_name|project_start_date|project_end_date|project_location|supplier_id|material_name|material_category|supplier_name|supplier_location|supplier_rating|\n",
      "+-----------+----------+------------------+--------------+----------------+--------+--------------+------------------+------------------+------------+------------------+----------------+----------------+-----------+-------------+-----------------+-------------+-----------------+---------------+\n",
      "|        290|        32|248950.37356851666|             1|      2020-01-01|       2|          Rail|168.03861162671606|138.93697900745806|  Project_32|        2022-08-31|      2023-02-28|          City_D|          1| Material_290|           Binder|   Supplier_1|           City_E|            2.0|\n",
      "|        973|        62| 96226.48180300942|             2|      2020-01-01|      74|          Rail|338.22773781549853| 3824.832060462899|  Project_62|        2025-02-28|      2025-08-28|          City_A|          5| Material_973|       Structural|   Supplier_5|           City_F|            4.0|\n",
      "|        447|         1| 378840.8485445615|             3|      2020-01-01|      54|         Truck|378.67837987449303| 3683.671228786419|   Project_1|        2020-01-31|      2020-07-31|          City_D|          5| Material_447|           Binder|   Supplier_5|           City_F|            4.0|\n",
      "|         49|        90| 270037.4610087137|             4|      2020-01-01|      24|         Truck| 190.1561492269182| 1152.487399883585|  Project_90|        2027-06-30|      2027-12-30|          City_D|          6|  Material_49|           Binder|   Supplier_6|           City_E|            1.0|\n",
      "|        781|        52|152404.84224091633|             5|      2020-01-01|      10|         Truck| 410.9108264233291|   2677.8490194696|  Project_52|        2024-04-30|      2024-10-30|          City_A|          3| Material_781|           Binder|   Supplier_3|           City_G|            5.0|\n",
      "|         38|        42| 76142.59103470482|             6|      2020-01-01|      16|         Drone|277.85514705624684|1132.4382539264209|  Project_42|        2023-06-30|      2023-12-30|          City_A|         10|  Material_38|       Insulation|  Supplier_10|           City_F|            3.0|\n",
      "|        398|        68|214864.93793364422|             7|      2020-01-01|       7|         Truck|266.75006573668037| 336.6643318552656|  project_68|        2025-08-31|      2026-02-28|          City_A|          5| Material_398|           Binder|   Supplier_5|           City_F|            4.0|\n",
      "|         12|        91|249009.00211573683|             8|      2020-01-01|      66|         Truck|122.79639289470099| 3142.658146509346|  Project_91|        2027-07-31|      2028-01-31|          City_B|          2|  Material_12|       Insulation|   Supplier_2|           City_E|            5.0|\n",
      "|        170|        84| 462789.0637229991|             9|      2020-01-01|      65|         Truck|474.17383408650943| 7014.657344076113|  project_84|        2026-12-31|      2027-06-30|          City_B|          2| Material_170|       Structural|   Supplier_2|           City_E|            5.0|\n",
      "|        500|        43|111018.97531515686|            10|      2020-01-01|      58|          Rail|266.75006573668037| 6648.723846354253|  Project_43|        2023-07-31|      2024-01-31|          City_C|          5| Material_500|       Insulation|   Supplier_5|           City_F|            4.0|\n",
      "+-----------+----------+------------------+--------------+----------------+--------+--------------+------------------+------------------+------------+------------------+----------------+----------------+-----------+-------------+-----------------+-------------+-----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading df\n",
    "final_df = spark.read.parquet(FINAL_DATA_parquet)\n",
    "\n",
    "final_df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for material_id:\n",
      "Mean: 496.76872549019606\n",
      "Max: 1000\n",
      "Min: 1\n",
      "Standard Deviation: 290.96310745073055\n",
      "Median: 497.0\n",
      "--------------\n",
      "Statistics for project_id:\n",
      "Mean: 50.42980392156863\n",
      "Max: 100\n",
      "Min: 1\n",
      "Standard Deviation: 28.75723049387397\n",
      "Median: 51.0\n",
      "--------------\n",
      "Statistics for project_budget:\n",
      "Mean: 295840.8306163639\n",
      "Max: 1950581.5483643755\n",
      "Min: 53805.64013990858\n",
      "Standard Deviation: 209570.71331281099\n",
      "Median: 270037.4610087137\n",
      "--------------\n",
      "Statistics for transaction_id:\n",
      "Mean: 5006.130980392157\n",
      "Max: 10000\n",
      "Min: 1\n",
      "Standard Deviation: 2884.331836773124\n",
      "Median: 5009.0\n",
      "--------------\n",
      "Statistics for transaction_date:\n",
      "Mean: None\n",
      "Max: 31/10/2021\n",
      "Min: 01/01/2021\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for quantity:\n",
      "Mean: 50.396470588235296\n",
      "Max: 99\n",
      "Min: 1\n",
      "Standard Deviation: 28.470351337471453\n",
      "Median: 50.0\n",
      "--------------\n",
      "Statistics for transport_mode:\n",
      "Mean: None\n",
      "Max: Truck\n",
      "Min: Drone\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for distance_covered:\n",
      "Mean: 304.99896981195866\n",
      "Max: 4989.07372254418\n",
      "Min: 10.00929808408966\n",
      "Standard Deviation: 409.6849422645481\n",
      "Median: 266.75006573668037\n",
      "--------------\n",
      "Statistics for CO2_emission:\n",
      "Mean: 3878.3788220057672\n",
      "Max: 22261.41573065918\n",
      "Min: 3.160525025280295\n",
      "Standard Deviation: 3808.2366286280417\n",
      "Median: 2677.8490194696\n",
      "--------------\n",
      "Statistics for project_name:\n",
      "Mean: None\n",
      "Max: project_84\n",
      "Min: Project_1\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for project_location:\n",
      "Mean: None\n",
      "Max: City_D\n",
      "Min: City_A\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for supplier_id:\n",
      "Mean: 5.350294117647059\n",
      "Max: 10\n",
      "Min: 1\n",
      "Standard Deviation: 2.8873241523300095\n",
      "Median: 5.0\n",
      "--------------\n",
      "Statistics for material_name:\n",
      "Mean: None\n",
      "Max: Material_999\n",
      "Min: Material_1\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for material_category:\n",
      "Mean: None\n",
      "Max: Structural\n",
      "Min: Binder\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for supplier_name:\n",
      "Mean: None\n",
      "Max: Supplier_9\n",
      "Min: Supplier_1\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for supplier_location:\n",
      "Mean: None\n",
      "Max: City_G\n",
      "Min: City_E\n",
      "Standard Deviation: None\n",
      "Median: N/A\n",
      "--------------\n",
      "Statistics for supplier_rating:\n",
      "Mean: 3.364313725490196\n",
      "Max: 5.0\n",
      "Min: 1.0\n",
      "Standard Deviation: 1.5019747172923015\n",
      "Median: 4.0\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics\n",
    "summary_stats = final_df.describe()\n",
    "\n",
    "# Fetch the statistics for each column from the summary DataFrame\n",
    "means = {row['summary']: row.asDict() for row in summary_stats.collect()}[\"mean\"]\n",
    "maxs = {row['summary']: row.asDict() for row in summary_stats.collect()}[\"max\"]\n",
    "mins = {row['summary']: row.asDict() for row in summary_stats.collect()}[\"min\"]\n",
    "stddevs = {row['summary']: row.asDict() for row in summary_stats.collect()}[\"stddev\"]\n",
    "\n",
    "# calculate median for each numerical column\n",
    "medians = {}\n",
    "for column in final_df.columns:\n",
    "    # Check if column is numerical by trying to cast it to a double; skip if casting fails (essentially changing the var type)\n",
    "    try:\n",
    "        final_df_numerical = final_df.withColumn(column, final_df[column].cast('double'))\n",
    "        medians[column] = final_df_numerical.approxQuantile(column, [0.5], 0.0)[0]\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# Display stats for each column\n",
    "for column in final_df_numerical.columns:\n",
    "    if column in means:  # This checks if the column is numerical (present in the summary stats)\n",
    "        print(f\"Statistics for {column}:\")\n",
    "        print(f\"Mean: {means[column]}\")\n",
    "        print(f\"Max: {maxs[column]}\")\n",
    "        print(f\"Min: {mins[column]}\")\n",
    "        print(f\"Standard Deviation: {stddevs[column]}\")\n",
    "        print(f\"Median: {medians.get(column, 'N/A')}\")\n",
    "        print(\"--------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARDINALITY: number of unique values for each of the specified categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality of transport_mode: 3\n",
      "Cardinality of project_location: 4\n",
      "Cardinality of material_category: 3\n",
      "Cardinality of supplier_location: 3\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\"transport_mode\", \"project_location\", \"material_category\", \"supplier_location\"]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    distinct_count = final_df.select(column).distinct().count()\n",
    "    print(f\"Cardinality of {column}: {distinct_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION BETWEEN NUMERICAL FEATURES AND TARGET FEATURE CO2_EMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between CO2_emissions and material_id is: 0.013309843960719402\n",
      "The correlation between CO2_emissions and project_id is: 0.015389057139567884\n",
      "The correlation between CO2_emissions and project_budget is: -0.008704442492230928\n",
      "The correlation between CO2_emissions and transaction_id is: 0.011334588931078056\n",
      "The correlation between CO2_emissions and quantity is: 0.5558180227071717\n",
      "The correlation between CO2_emissions and distance_covered is: 0.21013827019533382\n",
      "The correlation between CO2_emissions and supplier_id is: -0.01578169754900137\n",
      "The correlation between CO2_emissions and supplier_rating is: 0.00353117673371521\n"
     ]
    }
   ],
   "source": [
    "# List of features\n",
    "features = final_df.columns\n",
    "features.remove('CO2_emission')  # Remove the target variable\n",
    "\n",
    "# Calculate correlations with the target variable\n",
    "correlations = [(feature, final_df.stat.corr(feature, 'CO2_emission')) for feature in features if final_df.select(feature).dtypes[0][1] in ('double', 'int')]\n",
    "\n",
    "for feature in correlations:\n",
    "    print(f\"The correlation between CO2_emissions and {feature[0]} is: {feature[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that \"Quantity\" and \"Distance Covered\" are somewhat correlated with the target variable, I can create polynomial features to capture non-linear relationship. An interaction term can capture the combined effect of two variables. For example, the interaction between \"Quantity\" and \"Distance Covered\" might be informative.\n",
    "\n",
    "Creating polynomial features can be a useful step in capturing non-linear relationships between the features and the target variable. In a linear model, each feature is multiplied by a weight and summed up to make a prediction. This assumes that the relationship between each feature and the target variable is linear, but the real-world relationship between variables can often be more complex and non-linear.\n",
    "\n",
    "For example, the relationship between \"Quantity\" and \"CO2_emission\" might not be a straight line; it could be a curve. In such cases, simply using the \"Quantity\" feature as-is in a linear model might not capture this curve effectively. But if you add a new feature that is \"Quantity\" squared, the model has a better chance of capturing this curved relationship.\n",
    "\n",
    "The same logic applies to \"Distance Covered,\" or any interaction terms between \"Quantity\" and \"Distance Covered.\" By including these polynomial and interaction terms, you allow the model to fit to a more flexible, potentially non-linear function, which could result in a more accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features for 'Quantity' and 'Distance Covered'\n",
    "final_df = final_df.withColumn(\"Quantity_Squared\", col(\"Quantity\")**2)\n",
    "final_df = final_df.withColumn(\"Distance_Covered_Squared\", col(\"Distance_Covered\")**2)\n",
    "\n",
    "# Create interaction term between 'Quantity' and 'Distance Covered'\n",
    "final_df = final_df.withColumn(\"Quantity_Distance_Interaction\", col(\"Quantity\") * col(\"Distance_Covered\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Output column transport_mode_Index already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\ML-pipeline-Co2\\src\\data_preprocessing.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/christian/Documents/Workspace/ML-OPS/ML-pipeline-Co2/src/data_preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(stages\u001b[39m=\u001b[39mindexers \u001b[39m+\u001b[39m encoders)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/christian/Documents/Workspace/ML-OPS/ML-pipeline-Co2/src/data_preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Fit and transform the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/christian/Documents/Workspace/ML-OPS/ML-pipeline-Co2/src/data_preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m final_df \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit(final_df)\u001b[39m.\u001b[39mtransform(final_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/christian/Documents/Workspace/ML-OPS/ML-pipeline-Co2/src/data_preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Show transformed DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/christian/Documents/Workspace/ML-OPS/ML-pipeline-Co2/src/data_preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m final_df\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39mtransport_mode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtransport_mode_Index\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtransport_mode_OHE\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/christian/Documents/Workspace/ML-OPS/ML-pipeline-Co2/src/data_preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mproject_location\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mproject_location_Index\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mproject_location_OHE\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(dataset)\n\u001b[0;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\pyspark\\ml\\pipeline.py:134\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    132\u001b[0m     dataset \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39mtransform(dataset)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# must be an Estimator\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     model \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39;49mfit(dataset)\n\u001b[0;32m    135\u001b[0m     transformers\u001b[39m.\u001b[39mappend(model)\n\u001b[0;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(dataset)\n\u001b[0;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, dataset: DataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JM:\n\u001b[1;32m--> 381\u001b[0m     java_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_java(dataset)\n\u001b[0;32m    382\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    383\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 378\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mfit(dataset\u001b[39m.\u001b[39;49m_jdf)\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\christian\\Documents\\Workspace\\ML-OPS\\MLops-venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Output column transport_mode_Index already exists."
     ]
    }
   ],
   "source": [
    "# List of categorical columns\n",
    "categorical_columns = [\"transport_mode\", \"project_location\", \"material_category\", \"supplier_location\"]\n",
    "\n",
    "# Empty lists to hold our StringIndexers and OneHotEncoders\n",
    "indexers = []\n",
    "encoders = []\n",
    "\n",
    "# Loop through categorical columns and create StringIndexer and OneHotEncoder for each\n",
    "for column in categorical_columns:\n",
    "    # Create StringIndexer\n",
    "    indexer = StringIndexer(inputCol=column, outputCol=f\"{column}_Index\")\n",
    "    \n",
    "    # Create OneHotEncoder\n",
    "    encoder = OneHotEncoder(inputCol=f\"{column}_Index\", outputCol=f\"{column}_OHE\")\n",
    "    \n",
    "    # Append to our lists\n",
    "    indexers.append(indexer)\n",
    "    encoders.append(encoder)\n",
    "\n",
    "# Create pipeline for indexers and encoders\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "\n",
    "# Fit and transform the data\n",
    "final_df = pipeline.fit(final_df).transform(final_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Year, Month, and Day from 'Transaction_Date'\n",
    "final_df = final_df.withColumn(\"Transaction_Year\", year(\"Transaction_Date\"))\n",
    "final_df = final_df.withColumn(\"Transaction_Month\", month(\"Transaction_Date\"))\n",
    "final_df = final_df.withColumn(\"Transaction_Day\", dayofmonth(\"Transaction_Date\"))\n",
    "final_df = final_df.withColumn(\"is_weekend\", (dayofweek(\"transaction_date\").isin([1, 7])).cast(\"int\"))\n",
    "final_df = final_df.withColumn(\"project_duration\", datediff(\"project_end_date\", \"project_start_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+--------------+----------------+--------+--------------+------------------+------------------+------------+------------------+----------------+----------------+-----------+-------------+-----------------+-------------+-----------------+---------------+----------------+------------------------+-----------------------------+--------------------+----------------------+-----------------------+-----------------------+------------------+--------------------+---------------------+---------------------+----------------+-----------------+---------------+----------+----------------+\n",
      "|material_id|project_id|    project_budget|transaction_id|transaction_date|quantity|transport_mode|  distance_covered|      CO2_emission|project_name|project_start_date|project_end_date|project_location|supplier_id|material_name|material_category|supplier_name|supplier_location|supplier_rating|Quantity_Squared|Distance_Covered_Squared|Quantity_Distance_Interaction|transport_mode_Index|project_location_Index|material_category_Index|supplier_location_Index|transport_mode_OHE|project_location_OHE|material_category_OHE|supplier_location_OHE|Transaction_Year|Transaction_Month|Transaction_Day|is_weekend|project_duration|\n",
      "+-----------+----------+------------------+--------------+----------------+--------+--------------+------------------+------------------+------------+------------------+----------------+----------------+-----------+-------------+-----------------+-------------+-----------------+---------------+----------------+------------------------+-----------------------------+--------------------+----------------------+-----------------------+-----------------------+------------------+--------------------+---------------------+---------------------+----------------+-----------------+---------------+----------+----------------+\n",
      "|        290|        32|248950.37356851666|             1|      2020-01-01|       2|          Rail|168.03861162671606|138.93697900745806|  Project_32|        2022-08-31|      2023-02-28|          City_D|          1| Material_290|           Binder|   Supplier_1|           City_E|            2.0|             4.0|      28236.974997434314|            336.0772232534321|                 2.0|                   0.0|                    2.0|                    0.0|         (2,[],[])|       (3,[0],[1.0])|            (2,[],[])|        (2,[0],[1.0])|            2020|                1|              1|         0|             181|\n",
      "|        973|        62| 96226.48180300942|             2|      2020-01-01|      74|          Rail|338.22773781549853| 3824.832060462899|  Project_62|        2025-02-28|      2025-08-28|          City_A|          5| Material_973|       Structural|   Supplier_5|           City_F|            4.0|          5476.0|      114398.00262778961|            25028.85259834689|                 2.0|                   1.0|                    0.0|                    2.0|         (2,[],[])|       (3,[1],[1.0])|        (2,[0],[1.0])|            (2,[],[])|            2020|                1|              1|         0|             181|\n",
      "|        447|         1| 378840.8485445615|             3|      2020-01-01|      54|         Truck|378.67837987449303| 3683.671228786419|   Project_1|        2020-01-31|      2020-07-31|          City_D|          5| Material_447|           Binder|   Supplier_5|           City_F|            4.0|          2916.0|      143397.31538437086|           20448.632513222623|                 1.0|                   0.0|                    2.0|                    2.0|     (2,[1],[1.0])|       (3,[0],[1.0])|            (2,[],[])|            (2,[],[])|            2020|                1|              1|         0|             182|\n",
      "|         49|        90| 270037.4610087137|             4|      2020-01-01|      24|         Truck| 190.1561492269182| 1152.487399883585|  Project_90|        2027-06-30|      2027-12-30|          City_D|          6|  Material_49|           Binder|   Supplier_6|           City_E|            1.0|           576.0|       36159.36108880998|            4563.747581446037|                 1.0|                   0.0|                    2.0|                    0.0|     (2,[1],[1.0])|       (3,[0],[1.0])|            (2,[],[])|        (2,[0],[1.0])|            2020|                1|              1|         0|             183|\n",
      "|        781|        52|152404.84224091633|             5|      2020-01-01|      10|         Truck| 410.9108264233291|   2677.8490194696|  Project_52|        2024-04-30|      2024-10-30|          City_A|          3| Material_781|           Binder|   Supplier_3|           City_G|            5.0|           100.0|      168847.70727190332|            4109.108264233291|                 1.0|                   1.0|                    2.0|                    1.0|     (2,[1],[1.0])|       (3,[1],[1.0])|            (2,[],[])|        (2,[1],[1.0])|            2020|                1|              1|         0|             183|\n",
      "|         38|        42| 76142.59103470482|             6|      2020-01-01|      16|         Drone|277.85514705624684|1132.4382539264209|  Project_42|        2023-06-30|      2023-12-30|          City_A|         10|  Material_38|       Insulation|  Supplier_10|           City_F|            3.0|           256.0|       77203.48274564855|            4445.682352899949|                 0.0|                   1.0|                    1.0|                    2.0|     (2,[0],[1.0])|       (3,[1],[1.0])|        (2,[1],[1.0])|            (2,[],[])|            2020|                1|              1|         0|             183|\n",
      "|        398|        68|214864.93793364422|             7|      2020-01-01|       7|         Truck|266.75006573668037| 336.6643318552656|  project_68|        2025-08-31|      2026-02-28|          City_A|          5| Material_398|           Binder|   Supplier_5|           City_F|            4.0|            49.0|        71155.5975705233|           1867.2504601567625|                 1.0|                   1.0|                    2.0|                    2.0|     (2,[1],[1.0])|       (3,[1],[1.0])|            (2,[],[])|            (2,[],[])|            2020|                1|              1|         0|             181|\n",
      "|         12|        91|249009.00211573683|             8|      2020-01-01|      66|         Truck|122.79639289470099| 3142.658146509346|  Project_91|        2027-07-31|      2028-01-31|          City_B|          2|  Material_12|       Insulation|   Supplier_2|           City_E|            5.0|          4356.0|       15078.95410794977|            8104.561931050265|                 1.0|                   2.0|                    1.0|                    0.0|     (2,[1],[1.0])|       (3,[2],[1.0])|        (2,[1],[1.0])|        (2,[0],[1.0])|            2020|                1|              1|         0|             184|\n",
      "|        170|        84| 462789.0637229991|             9|      2020-01-01|      65|         Truck|474.17383408650943| 7014.657344076113|  project_84|        2026-12-31|      2027-06-30|          City_B|          2| Material_170|       Structural|   Supplier_2|           City_E|            5.0|          4225.0|      224840.82493230057|           30821.299215623112|                 1.0|                   2.0|                    0.0|                    0.0|     (2,[1],[1.0])|       (3,[2],[1.0])|        (2,[0],[1.0])|        (2,[0],[1.0])|            2020|                1|              1|         0|             181|\n",
      "|        500|        43|111018.97531515686|            10|      2020-01-01|      58|          Rail|266.75006573668037| 6648.723846354253|  Project_43|        2023-07-31|      2024-01-31|          City_C|          5| Material_500|       Insulation|   Supplier_5|           City_F|            4.0|          3364.0|        71155.5975705233|           15471.503812727462|                 2.0|                   3.0|                    1.0|                    2.0|         (2,[],[])|           (3,[],[])|        (2,[1],[1.0])|            (2,[],[])|            2020|                1|              1|         0|             184|\n",
      "+-----------+----------+------------------+--------------+----------------+--------+--------------+------------------+------------------+------------+------------------+----------------+----------------+-----------+-------------+-----------------+-------------+-----------------+---------------+----------------+------------------------+-----------------------------+--------------------+----------------------+-----------------------+-----------------------+------------------+--------------------+---------------------+---------------------+----------------+-----------------+---------------+----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
